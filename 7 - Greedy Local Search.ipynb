{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why?\n",
    "Optimization. How do we find the best hypotesis\n",
    "\n",
    "# What do we need?\n",
    "A successor function, showing what states we can reach with the current funciton. Usualy a distance measure\n",
    "\n",
    "An objective error function to tell us how good the current state is\n",
    "\n",
    "and enough memory to hold hte best state found so far, the current state, and the state its moving to\n",
    "\n",
    "## Hill climbing search\n",
    "Basically finds the max by scanning through the list and comparing values to see if current is better than the best state. Its prone to getting stuck on local maxima\n",
    "\n",
    "## Simulated annealing search\n",
    "Same as hill climbing search, but we escape local maxima by gradually decreasing the frequency of bad moves. \n",
    "\n",
    "## Local Beam Search\n",
    "\n",
    "State with K states rather than 1, and keep track of all k states. Each iteration generates all successors of the k states, until we hit the goal, otherwise we select the k best successors from the list and repeat again.\n",
    "\n",
    "## Continuous optimization \n",
    "\n",
    "Use packages\n",
    "\n",
    "* Stochastic vs Batch\n",
    "** Use stochastic first\n",
    "* Analytic gradients are hard to debug\n",
    "** Use packages with gradients built in like Tenserflow\n",
    "** do gradient checking yourself"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
