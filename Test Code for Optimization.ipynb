{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan of Attack\n",
    "\n",
    "1. Start by importing data sets\n",
    "2. Create variables to hold data sets\n",
    "3. create arbitrary path through data set\n",
    "4. find score of such set\n",
    "5. calculate gradient of set\n",
    "6. feed into optimizer???? <---- Hardest step\n",
    "7. optimize for each cycle you want to train for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data sets\n",
    "\n",
    "Data sets should, most likely, be in .csv file formats. In our case, our data set is very simple and can be expressed as an integer. \n",
    "\n",
    "This integer would tell us how many different components there are for us to optimize. Each component would be assigned a number from 0 to n arbitrarily. These numbers would need to be kept consistent throughout the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "dataSetSize = 40 #Number of points for the data set file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variable to hold order\n",
    "\n",
    "We need to create two variables, of size `dataset` to hold the the current optimal order and the working optimal order\n",
    "\n",
    "We can simply initialize those variables to random. To randomize a list of matrix, we can simply shuffle it using the random library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 10,\n",
       " 34,\n",
       " 26,\n",
       " 30,\n",
       " 19,\n",
       " 36,\n",
       " 12,\n",
       " 16,\n",
       " 17,\n",
       " 29,\n",
       " 4,\n",
       " 0,\n",
       " 23,\n",
       " 13,\n",
       " 25,\n",
       " 27,\n",
       " 21,\n",
       " 14,\n",
       " 32,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 28,\n",
       " 31,\n",
       " 37,\n",
       " 38,\n",
       " 8,\n",
       " 2,\n",
       " 35,\n",
       " 11,\n",
       " 18,\n",
       " 20,\n",
       " 24,\n",
       " 7,\n",
       " 22,\n",
       " 3,\n",
       " 5,\n",
       " 39,\n",
       " 33]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order = list(range(dataSetSize))\n",
    "random.shuffle(order)\n",
    "orderMax = order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
